{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sporting-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy\n",
    "#Chi-square test\n",
    "from scipy.stats import chi2_contingency, chi2\n",
    "#ANOVA test\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-heart",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "laden-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column: Noi_dung\n",
    "def noi_dung_clean(feature,df):\n",
    "    df[feature] = df[feature].str.lower()\n",
    "    index_lst=[]\n",
    "    for e in ['bán đất', 'villa', 'biệt thự', 'trọ ', 'căn hộ dịch vụ', 'khách sạn']:\n",
    "        for i in range(0, df.shape[0]):\n",
    "            if re.findall(e, df.Noi_dung[i]) != []:\n",
    "                index_lst.append(i)\n",
    "    df = df.drop(index_lst).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "excited-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column: Dien_tich, Dien_tich_su_dung\n",
    "def dien_tich_clean(feature_lst, df):\n",
    "    for feature in feature_lst:\n",
    "        df[feature] = df[feature].apply(lambda x: x if (type(x)==float) | (type(x)==int) \\\n",
    "                                              else float(re.sub(\"\\.\", \"\",x,1)))\n",
    "        df[feature] = df[feature].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "iraqi-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column: Gia\n",
    "def gia_clean(feature,df):\n",
    "    #Loại bỏ khoảng trắng 2 đầu, lowercase, split into list of strings\n",
    "    df[feature] = df[feature].apply(lambda x: x.strip().lower().split(' '))\n",
    "    #Loại bỏ dòng 'đã bán'\n",
    "    sold_index = []\n",
    "    for i in range(0, df.shape[0]):\n",
    "        if df[feature][i][0]=='đã':\n",
    "            sold_index.append(i)\n",
    "    df = df.drop(sold_index).reset_index(drop=True)\n",
    "    \n",
    "    for i in range(0, df.shape[0]):\n",
    "        #Đơn vị của tổng tiền là 'tỷ' => nhân 1000 để chuyển sang triệu\n",
    "        if df[feature][i][1] =='tỷ' or df[feature][i][1] =='tỉ':\n",
    "            df[feature][i] = float(df[feature][i][0].replace(',','.'))*1000\n",
    "        #Đơn vị của tổng tiền là 'triệu'\n",
    "        elif (df[feature][i][1] =='triệu') and (float(df['Gia'][i][0].replace(',','.')) >=500):\n",
    "            df[feature][i] = float(df[feature][i][0].replace(',','.'))\n",
    "        else:\n",
    "            df = df.drop(i)\n",
    "    df[feature] = df[feature].astype(float)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "purple-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column: Cau_truc\n",
    "def cau_truc_clean(feature,df):\n",
    "    for i in range(0, df.shape[0]):\n",
    "        count = 0\n",
    "        df[feature][i] = df[feature][i].replace(',',' ').replace('+', ' ').lower().split()\n",
    "        for e in df[feature][i]:\n",
    "            if e in ['hầm', 'hâm', 'trệt']:\n",
    "                count+=1\n",
    "            if e in ['lửng', 'lung', 'lưng','thượng', 'thuong']:\n",
    "                count+=0.5\n",
    "            if e in ['áp', 'gác', 'ap', 'gac']:\n",
    "                count+=0.5\n",
    "            if e in ['lầu', 'lâu', 'lau']:\n",
    "                count+=int(df[feature][i][df[feature][i].index(e)-1])   \n",
    "        df[feature][i] = float(count)\n",
    "    df[feature] = df[feature].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "numeric-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column: Tien_ich\n",
    "def count_tien_ich(lst_loai_tien_ich,lst_tien_ich):\n",
    "    count=0\n",
    "    for tien_ich in lst_loai_tien_ich:\n",
    "        if tien_ich in lst_tien_ich:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "def tien_ich_clean(feature, df):\n",
    "    df[feature] = df[feature].fillna('0')\n",
    "    df[feature] = df[feature].apply(lambda x: x.lower())\n",
    "    lst_loai_tien_ich = ['chợ','siêu thị','bệnh viện','công viên','trung tâm','trường học', 'để xe']\n",
    "    df[feature] = df[feature].apply(lambda x: count_tien_ich(lst_loai_tien_ich,x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "earlier-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column: So_phong, Nha_ve_sinh\n",
    "def so_phong_nvs_clean(feature, df):\n",
    "    mode = df[feature].mode()\n",
    "    for i in range(df.shape[0]):\n",
    "        if isinstance(df[feature][i], int)==False:\n",
    "            df[feature][i] = mode\n",
    "    df[feature] = df[feature].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "precise-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column: Quan, Phuong\n",
    "def phuong_quan_combine(feature1, feature2, new_feature, df):\n",
    "    df[feature1] = df[feature1].apply(lambda x: x.strip())\n",
    "    df[feature2] = df[feature2].apply(lambda x: x.strip())\n",
    "    df[new_feature] = df[feature1] + ', ' + df[feature2]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "brilliant-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column: Giay_to\n",
    "def giay_to_clean(feature, df):\n",
    "    df[feature] = df[feature].apply(lambda x: 1 if x=='Sổ hồng' or x =='Sổ đỏ' else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceramic-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column: Huong\n",
    "def huong_clean(feature, df):\n",
    "    huong_dict = {'Đ.Bắc':1, 'T.Nam':2, 'Bắc':3, 'Đ.Nam':4, 'T.Bắc':5, 'Đông':6, 'Nam':7, 'Tây':8,'Không xác định':0}\n",
    "    df[feature] = [huong_dict[i] for i in df[feature]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "editorial-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column: Hem_rong & Duong_mat_tien\n",
    "def hem_duong(feature1,feature2,new_feature,df):\n",
    "    for i in range(df.shape[0]):\n",
    "        if (df[feature1][i] !=0) & (df[feature2][i] !=0):\n",
    "            df[new_feature][i] = df[feature2][i]\n",
    "        else:\n",
    "            df[new_feature] = df[feature1] + df[feature2]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "painful-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_n_clean_data_train(train_data_file):\n",
    "    df = pd.read_excel(train_data_file, engine='openpyxl')\n",
    "    df1 = noi_dung_clean('Noi_dung',df)\n",
    "    df2 = gia_clean('Gia',df1)\n",
    "    df3 = dien_tich_clean(['Dien_tich','Dien_tich_su_dung'], df2)\n",
    "    df4 = cau_truc_clean('Cau_truc',df3)\n",
    "    df5 = tien_ich_clean('Tien_ich', df4)\n",
    "    df6 = so_phong_nvs_clean('So_phong', df5)\n",
    "    df7 = so_phong_nvs_clean('Nha_ve_sinh', df6)\n",
    "    df8 = phuong_quan_combine('Quan', 'Phuong','Dia_diem', df7)\n",
    "    df9 = giay_to_clean('Giay_to', df8)\n",
    "    df10 = huong_clean('Huong', df9)\n",
    "    df11 = hem_duong('Hem_rong','Duong_mat_tien','Hem_duong',df10)\n",
    "#     df12 =  drop_outliers(['So_phong','Dien_tich', 'Dien_tich_su_dung','Hem_duong'], df11)\n",
    "    df11 = df11.reset_index(drop=True)\n",
    "    return df11[['Gia','Nha_ve_sinh','Cau_truc', 'Dien_tich','Dien_tich_su_dung','Hem_duong',  \n",
    "                   'Duong','Dia_diem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "distributed-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column: Gia - Test data\n",
    "def gia_clean_test(feature,df):\n",
    "    df['Gia'] = df[feature]*1000\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bacterial-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_n_clean_data_test(test_data_file):\n",
    "    df1 = pd.read_excel(test_data_file, engine='openpyxl')\n",
    "    df2 = gia_clean_test('Gia (tỷ - dùng để đánh giá )',df1)\n",
    "    df3 = dien_tich_clean(['Dien_tich','Dien_tich_su_dung'], df2)\n",
    "    df4 = cau_truc_clean('Cau_truc',df3)\n",
    "    df5 = tien_ich_clean('Tien_ich', df4)\n",
    "    df6 = so_phong_nvs_clean('So_phong', df5)\n",
    "    df7 = so_phong_nvs_clean('Nha_ve_sinh', df6)\n",
    "    df8 = phuong_quan_combine('Quan', 'Phuong','Dia_diem', df7)\n",
    "    df9 = giay_to_clean('Giay_to', df8)\n",
    "    df10 = huong_clean('Huong', df9)\n",
    "    df11 = hem_duong('Hem_rong','Duong_mat_tien','Hem_duong',df10)\n",
    "    return df11[['Gia','Nha_ve_sinh','Cau_truc', 'Dien_tich','Dien_tich_su_dung','Hem_duong',  \n",
    "                   'Duong','Dia_diem']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-christian",
   "metadata": {},
   "source": [
    "### Univariate  analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-deficit",
   "metadata": {},
   "source": [
    "#### --Number variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "outstanding-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_cont_analysis(var,df):\n",
    "    mean = df[var].mean()\n",
    "    median = df[var].median() \n",
    "    mode = df[var].mode()\n",
    "    max_val = df[var].max()\n",
    "    min_val = df[var].min()\n",
    "    range_val = np.ptp(df[var])\n",
    "    variance = df[var].var()\n",
    "    skewness = df[var].skew()\n",
    "    kurtosis = df[var].kurtosis()\n",
    "    result = [mean,median,mode,max_val,min_val,range_val,variance,skewness,kurtosis]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cordless-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization - Histogram\n",
    "def visualize_histogram(cont_var, df):\n",
    "    if len(cont_var)%3 == 0:\n",
    "        n = len(cont_var)/3\n",
    "    else:\n",
    "        n = len(cont_var)//3 + 1\n",
    "    plt.figure(figsize=(15,15))\n",
    "    for i in range(1,len(cont_var)+1):\n",
    "        plt.subplot(n,3,i)\n",
    "        sns.distplot(df[cont_var[i-1]].dropna())\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "limited-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization - Boxplot\n",
    "def visualize_boxplot(cont_var, df):\n",
    "    if len(cont_var)%3 == 0:\n",
    "        n = len(cont_var)/3\n",
    "    else:\n",
    "        n = len(cont_var)//3 + 1\n",
    "    plt.figure(figsize=(15,15))\n",
    "    for i in range (1,len(cont_var)+1):\n",
    "        plt.subplot(n,3,i)\n",
    "        plt.boxplot(df[cont_var[i-1]].dropna())\n",
    "        plt.title(cont_var[i-1])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-function",
   "metadata": {},
   "source": [
    "#### --Catergorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "becoming-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization - Value_count - barplot\n",
    "def visualize_cat_value_count(cat_var, df):\n",
    "    if len(cat_var)%3 == 0:\n",
    "        n = len(cat_var)/3\n",
    "    else:\n",
    "        n = len(cat_var)//3 + 1\n",
    "    plt.figure(figsize=(15,6))\n",
    "    for i in range (1,len(cat_var)+1):\n",
    "        count = df.groupby(df[cat_var[i-1]].dropna()).size()\n",
    "        #print(count)\n",
    "        plt.subplot(n,3,i)\n",
    "        count.plot.bar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-royal",
   "metadata": {},
   "source": [
    "### Bivariate  analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "invisible-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "##continuous - continuous \n",
    "def visualize_heatmap(cont_var, df):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    sns.heatmap(df[cont_var].corr(), cmap=\"YlGnBu\", annot=True,square=True, linewidths=.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "turkish-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical - output(cont) \n",
    "def visualize_boxplot_cat_output(cat_var, output, df):\n",
    "    if len(cat_var)%3 == 0:\n",
    "        n = len(cat_var)/3\n",
    "    else:\n",
    "        n = len(cat_var)//3 + 1\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for i in range(1,len(cat_var)+1):\n",
    "        df_melt = df[[cat_var[i-1],output]]\n",
    "        plt.subplot(n,3,i)\n",
    "        sns.boxplot(data=df_melt,x=cat_var[i-1],y=output )\n",
    "        i+=1\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adolescent-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical - output(cont) \n",
    "# Anova Test\n",
    "\n",
    "def anova_test(cat_var, output, df):\n",
    "    dependent_cat_list = []\n",
    "    for var in cat_var:\n",
    "        model = ols(' '+ output +'~ C(' + var + ')', df).fit()\n",
    "        anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "        #display(anova_table)\n",
    "        if anova_table['PR(>F)'][0] < 0.05:\n",
    "            #print(var,'p-value:',anova_table['PR(>F)'][0])\n",
    "            #print('==> Dependent (Reject H0)')\n",
    "            dependent_cat_list.append(var)\n",
    "    return dependent_cat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "divided-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categgorical - categorical\n",
    "def chi2_test(cat_var,df):\n",
    "    chi2_test_df=pd.DataFrame(index=cat_var,columns=cat_var)\n",
    "    alpha = 0.05\n",
    "\n",
    "    for i in range (len(cat_var)):\n",
    "        for j in range(i+1,len(cat_var)):\n",
    "            table = pd.crosstab(df[cat_var[i]],df[cat_var[j]])\n",
    "            stat, p, dof, expected = chi2_contingency(table)\n",
    "            #print('\\n*** significance = %.3f, p_value = %.3f' %(alpha,p))\n",
    "            if p < alpha:\n",
    "                #print(cat_var[i],'&',cat_var[j],'==> Dependent (Reject H0)')\n",
    "                chi2_test_df.loc[cat_var[i],cat_var[j]]='Dependent'\n",
    "            else:\n",
    "                #print(cat_var[i],'&',cat_var[j],'==> Independent (Fail to Reject H0)')\n",
    "                chi2_test_df.loc[cat_var[i],cat_var[j]]='Independent'\n",
    "    return chi2_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-monitor",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hearing-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outliers(cont_vars, df):\n",
    "    for cont_var in cont_vars:\n",
    "        upper_limit= np.quantile(df[cont_var],0.75) + 1.5*scipy.stats.iqr(df[cont_var])\n",
    "        lower_limit= np.quantile(df[cont_var],0.25) - 1.5*scipy.stats.iqr(df[cont_var])\n",
    "        df = df[ (df[cont_var]>=lower_limit) & (df[cont_var]<=upper_limit)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "conscious-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_outliers(cont_vars,df):\n",
    "    df_outliers = pd.DataFrame(index=cont_vars, columns=['upper_outliers','lower_outliers','outlier_per'])\n",
    "    for cont_var in cont_vars:\n",
    "        upper_outliers = len(df[cont_var][df[cont_var] > (np.quantile(df[cont_var],0.75) + 1.5*scipy.stats.iqr(df[cont_var]))])\n",
    "        lower_outliers = len(df[cont_var][df[cont_var] < (np.quantile(df[cont_var],0.25) - 1.5*scipy.stats.iqr(df[cont_var]))])\n",
    "        outlier_per = (upper_outliers + lower_outliers)/len(df[cont_var])\n",
    "        df_outliers.loc[cont_var,'upper_outliers']=upper_outliers\n",
    "        df_outliers.loc[cont_var,'lower_outliers']=lower_outliers\n",
    "        df_outliers.loc[cont_var,'outlier_per']=round(outlier_per,2)*100\n",
    "    return df_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-characterization",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "continent-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average_Score_Model(model, X, y, size=0.25, cv=5):\n",
    "    score_train=[]\n",
    "    score_test=[]\n",
    "    duration=[]\n",
    "    ## Thực hiện lặp cv lần, mỗi lần lặp: tách X,y -> tính accuracy của train và test, time đưa vào danh sách\n",
    "    for i in range(1,cv+1):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=size) \n",
    "        start = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        end = time.time()\n",
    "        score_train.append(model.score(X_train,y_train))\n",
    "        score_test.append(model.score(X_test,y_test))\n",
    "        duration.append((end-start)*1000)\n",
    "    return np.mean(score_test),np.mean(duration) #trung bình score_train, score_test, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "egyptian-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model_evaluation(model_name, model,X_train,y_train,X_test,y_test):\n",
    "    yhat_test = model.predict(X_test)\n",
    "    # tinh R^2\n",
    "    R2_train = model.score(X_train,y_train)\n",
    "    R2_test = model.score(X_test,y_test)\n",
    "    # tinh RMSE\n",
    "    mse_test = mean_squared_error(y_true=y_test, y_pred=yhat_test)\n",
    "    rmse_test = math.sqrt(mse_test)\n",
    "    #result\n",
    "    result = pd.DataFrame([[R2_train,R2_test,rmse_test]],\n",
    "                          columns=['R2_train','R2_test','RMSE_test'],\n",
    "                          index=[model_name])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "exterior-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model_evaluation2(model,X, y):\n",
    "    yhat = model.predict(X)\n",
    "    # tinh R^2\n",
    "    R2_score = model.score(X, y)\n",
    "    # tinh RMSE\n",
    "    mse = mean_squared_error(y, yhat)\n",
    "    rmse= math.sqrt(mse)\n",
    "    #result\n",
    "    result = pd.DataFrame([[R2_score,rmse]],\n",
    "                          columns=['R2_score','rmse'],\n",
    "                          index=['Result'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "unexpected-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cau_truc_func_1(lst_cau_truc):\n",
    "#     new_lst_cau_truc=[]\n",
    "#     for i in range(0, len(lst_cau_truc)): \n",
    "#         cau_truc = re.findall(r'\\D+', lst_cau_truc[i])[0]\n",
    "#         so_luong = re.findall(r'\\d+', lst_cau_truc[i])\n",
    "#         if len(so_luong)==0:\n",
    "#             so_luong = 0\n",
    "#         else:\n",
    "#             so_luong=int(so_luong[0])\n",
    "#         new_lst_cau_truc.append(cau_truc)\n",
    "#         new_lst_cau_truc.append(so_luong)      \n",
    "#     return new_lst_cau_truc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "sealed-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cau_truc_func_2(loai_cau_truc,new_lst_cau_truc):\n",
    "#     if loai_cau_truc in new_lst_cau_truc:\n",
    "#         if loai_cau_truc == 'cótầnghầm':\n",
    "#             so_luong = 1\n",
    "#         else:\n",
    "#         #tên cấu trúc có trong new_lst_cau_truc\n",
    "#             index=new_lst_cau_truc.index(loai_cau_truc)\n",
    "#             so_luong=new_lst_cau_truc[index+1]\n",
    "#         return so_luong\n",
    "#     else:\n",
    "#         #tên cấu trúc không có trong new_lst_cau_truc\n",
    "#         return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-transformation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
